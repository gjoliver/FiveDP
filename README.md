The repo demonstrates torch native data parallel, fsdp, context parallel, tensor parallel, and sequence parallel applied at the same time to a tiny GPT2 model.
